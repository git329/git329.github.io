---
layout: post
title: "Hadoop 文件压缩"
description: "Hadoop"
category: articles
tags: [Hadoop]
comments: true
---
Hadoop 文件类型及压缩
=======
####  Reference
<http://www.infoq.com/cn/articles/hadoop-file-format>
#### 压缩
在考虑由MapReduce处理数据时，压缩格式是否支持切分（splitting）是非常重要的。
| 压缩格式 | 切分 | 算法 |
| :------- | :--- | :------- |
|gzip|不支持|DEFLATE|
|DEFLATE|不支持|DEFLATE|
|LZO|不支持|LZO|
|LZ4|不支持|LZ4|
|snappy|不支持|Snappy|
|bzip2|<font color="HotPink">支持</font>|bzip2|

<font color="HotPink">注意:</font></br>
如果LZO文件以及在预处理中别索引了，那么它就支持切分。

### Avro文件
Avro的对象容器文件格式主要用于存储Avro对象序列。</br>
<font color="HotPink">可切分</font>
### SequenceFile
SequenceFile也可以作为小文件的容器。HDFS和MapReduce是针对大文件优化的，因此通过SequenceFile类型把小文件包装起来可以获得更高效率的</br>
首先，我们需要明白的SequenceFile想要解决的问题是什么？</br>
**In HDFS**
1. 在Hadoop里，SequenceFile是其中一种用来解决小文件的solution。
2. 小文件是指比HDFS的block size（128 MB）都要小得多的文件。
3. 在HDFS中，每一个文件，目录，block都被认为是object，占用150个字节。
4. 那比如1千万个文件，就要占用掉Namenode中大概3G的内存
5. 如果文件个数上billion（十亿），那更是恼火，基本上不可行了。
**In MapReduce**
1. Map Task通常一次处理一个block的input（如果采用默认的FileInputFormat）
2. 那么更多的文件，就需要更多的map task，那么job的时长就会增加。
**Small File Scenarios**
1. 这些小文件可能是一个大文件的片段
方案：写一个程序把这些小文件拼接起来
2. 这些小文件天生就小，比如image
方案：可能需要某种container把这些小文件装载
**Solutions in Hadoop**
*HAR Files*
HAR（Hadoop Archives)的引入是为了减轻namenode的内存压力，HAR的最佳使用就是为了存储的archive。
*SequenceFile*
1. SequenceFile的概念就是把多个下文件放到一个大点的文件。比如哈，假设现在有10，000个100KB的文件，我们可以写一个程序，把他们都放到一个SequenceFile里，你可以使用文件名作为key，内容作为value。文件结构如下：
![](hadoop-文件压缩-SequencFile Layout)
2. 好处：
[TAB]. NameNode需要更小的内存，还是拿这1w个100kB的小文件举例哈，如果没有使用SequenceFile，这1w个objects占用Nameno的4.5MB RAM。那么使用了SequenceFile以后，1GB的SequenceFile有8个HDFS的block（1024MB/128MB)，而这8个object就只需要占用Namenode上3.6kb的RAM。
[TAB]. SequenceFiles是可切分的（splittable），而且支持压缩的。所以适用于MapReduce
## Hadoop 中的文件格式
#### SequenceFile
SequenceFile是Hadoop API 提供的一种二进制文件，它将数据以<key,value>的形式序列化到文件中。
### Map文件
Map File是已经拍过序的SequenceFile，有索引。
### RC文件
RC File是Hive推出的一种专门面向列的数据格式。当查询过程中，针对它并不关心的列时，它会在IO上跳过这些列，但是在读取所有列的情况下，RCFile的性能反而没有SequenceFile高
#### Avro
Avro是一种用于支持数据密集型的二进制文件格式。Avro能够提供更好的序列化和反序列化性能。并且Avro数据文件天生是带Schema定义的，所以它不需要开发者在API 级别实现自己的Writable对象
#### 文本格式
除上面提到的3种二进制格式之外，文本格式的数据也是Hadoop中经常碰到的。如TextFile 、XML和JSON。 文本格式除了会占用更多磁盘资源外，对它的解析开销一般会比二进制格式高几十倍以上，尤其是XML 和JSON，它们的解析开销比Textfile 还要大，因此强烈不建议在生产系统中使用这些格式进行储存。
#### 文件存储大小比较与分析
SequenceFile无论在压缩和非压缩的情况下都比原始纯文本TextFile大，其中非压缩模式下大11%， 压缩模式下大6.4%。这跟SequenceFile的文件格式的定义有关： SequenceFile在文件头中定义了其元数据，元数据的大小会根据压缩模式的不同略有不同。一般情况下，压缩都是选取block 级别进行的，每一个block都包含key的长度和value的长度，另外每4K字节会有一个sync-marker的标记。对于TextFile文件格式来说不同列之间只需要用一个行间隔符来切分，所以TextFile文件格式比SequenceFile文件格式要小。但是TextFile 文件格式不定义列的长度，所以它必须逐个字符判断每个字符是不是分隔符和行结束符。因此TextFile 的反序列化开销会比其他二进制的文件格式高几十倍以上。</br>

RCFile文件格式同样也会保存每个列的每个字段的长度。但是它是连续储存在头部元数据块中，它储存实际数据值也是连续的。另外RCFile 会每隔一定块大小重写一次头部的元数据块（称为row group，由hive.io.rcfile.record.buffer.size控制，其默认大小为4M），这种做法对于新出现的列是必须的，但是如果是重复的列则不需要。RCFile 本来应该会比SequenceFile 文件大，但是RCFile 在定义头部时对于字段长度使用了Run Length Encoding进行压缩，所以RCFile 比SequenceFile又小一些。Run length Encoding针对固定长度的数据格式有非常高的压缩效率，比如Integer、Double和Long等占固定长度的数据类型。在此提一个特例——Hive 0.8引入的TimeStamp 时间类型，如果其格式不包括毫秒，可表示为”YYYY-MM-DD HH:MM:SS”，那么就是固定长度占8个字节。如果带毫秒，则表示为”YYYY-MM-DD HH:MM:SS.fffffffff”，后面毫秒的部分则是可变的。</br>

Avro文件格式也按group进行划分。但是它会在头部定义整个数据的模式（Schema）， 而不像RCFile那样每隔一个row group就定义列的类型，并且重复多次。另外，Avro在使用部分类型的时候会使用更小的数据类型，比如Short或者Byte类型，所以Avro的数据块比RCFile 的文件格式块更小。</br>
### Snappy
