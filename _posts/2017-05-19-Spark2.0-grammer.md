---
layout: post
title: "Spark2.0 新语法"
description: "Spark入门"
category: articles
tags: [Spark]
comments: true
---
Spark 2.0, DataFrames
=====================

## DataSet操作
### 描述
DataFrames provide a domain-specific language for structured data manipulation in Scala, Java, Python and R.

As mentioned above, in Spark 2.0, DataFrames are just Dataset of Rows in Scala and Java API. These operations are also referred as “untyped transformations” in contrast to “typed transformations” come with strongly typed Scala/Java Datasets.

### SparkSession
```scala
scala> import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.SparkSession
scala> var spark=SparkSession.builder.appName("Spark SQL Study").getOrCreate
17/05/19 08:42:06 WARN sql.SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@7d9c448f
scala> val df=spark.read.json("people.json")
df: org.apache.spark.sql.DataFrame = [age: bigint, name: string]

scala> df.show
+----+-------+
| age|   name|
+----+-------+
|null|Michael|
|  30|   Andy|
|  19| Justin|
+----+-------+
```
## SQL查询

### registerTempTable
```scala
scala> val sqlDf=spark.sql("select * from People")
sqlDf: org.apache.spark.sql.DataFrame = [age: bigint, name: string]
scala> sqlDf.show()
+----+-------+
| age|   name|
+----+-------+
|null|Michael|
|  30|   Andy|
|  19| Justin|
+----+-------+
```
